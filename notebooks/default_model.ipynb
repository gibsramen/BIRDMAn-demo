{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "median-islam",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**B**ayesian **I**nferential **R**egression for **D**ifferential **M**icrobiome **A**nalysis (BIRDMAn) is a WIP tool for flexible differential abundance analysis through Bayesian inference. BIRDMAn is unique in that it has been designed to support custom statistical modelling. Other tools implement specific models designed for general use cases. BIRDMAn, on the other hand, makes use of the [Stan](https://mc-stan.org/) probabilistic programming language for model specification. The overall goal of this software is to allow users to specify their own statistical models to address their individual experimental design/questions.\n",
    "\n",
    "BIRDMAn also includes several default models for those who do not wish to tinker with custom Stan models. In this demo notebook, we'll walkthrough fitting the default Negative Binomial model to some example data. For more information see Jamie's [blogpost](https://mortonjt.github.io/probable-bug-bytes/probable-bug-bytes/differential-abundance/) that inspired this project.\n",
    "\n",
    "**NOTE:** BIRDMAn is still in development and things are likely to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-soundtrack",
   "metadata": {},
   "source": [
    "# Preprocessing feature table\n",
    "\n",
    "We will be using data from the study \"Responses of gut microbiota to diet composition and weight loss in lean and obese mice\" (Qiita ID: 107). This study looks at the effect of weight loss and diet composition on the gut microbiome.\n",
    "\n",
    "We will first process and explore the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import biom\n",
    "\n",
    "raw_tbl = biom.load_table(\"../data/lean_obese_mice/44773_otu_table.biom\")\n",
    "raw_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tbl_df = raw_tbl.to_dataframe()\n",
    "raw_tbl_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-negative",
   "metadata": {},
   "source": [
    "For this demo we are going to use a small subset of the OTUs present in this table based on prevalence (present in at least 20 samples). This is done primarily to let the models run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = raw_tbl_df.clip(upper=1).sum(axis=1)\n",
    "filt_tbl_df = raw_tbl_df.loc[prev[prev >= 20].index, :]\n",
    "filt_tbl_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-cruise",
   "metadata": {},
   "source": [
    "BIRDMAn expects tables to be input in BIOM format so we save our filtered table in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_tbl = biom.table.Table(\n",
    "    filt_tbl_df.values,\n",
    "    sample_ids=filt_tbl_df.columns,\n",
    "    observation_ids=filt_tbl_df.index\n",
    ")\n",
    "filt_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-father",
   "metadata": {},
   "source": [
    "# Exploring metadata\n",
    "\n",
    "Given the title of this study, we are going to be focused on weight loss and diet as covariates in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv(\n",
    "    \"../data/lean_obese_mice/107_20180101-113755.txt\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=0\n",
    ")\n",
    "metadata.index = metadata.index.astype(str)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.groupby([\"diet\", \"treatment\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-drama",
   "metadata": {},
   "source": [
    "We will consider diet, treatment, and their interaction in our regression model. Importantly, we will specify that we want to keep `Control` and `Ad Lib` as the respective reference values (same way as in Songbird)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-table",
   "metadata": {},
   "source": [
    "# Running BIRDMAn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-router",
   "metadata": {},
   "source": [
    "Now it's time to run BIRDMAn! To save on computation time we will only specify 100 iterations per chain. For actual modelling you will likely want this value to be higher (defaults to 500).\n",
    "\n",
    "Every BIRDMAn takes several parameters that I will outline here:\n",
    "\n",
    "* `table`: BIOM table of features x samples\n",
    "* `formula`: Formula with which to fit model (same as in Songbird)\n",
    "* `metadata`: DataFrame with columns specified in `formula`\n",
    "* `num_iter`: Number of iterations of MCMC sampling to run *per chain*\n",
    "* `chains`: Number of chains to run\n",
    "\n",
    "For the default Negative Binomial model we can also include the prior values for $\\beta$ and $\\phi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdman import NegativeBinomial\n",
    "\n",
    "nb = NegativeBinomial(\n",
    "    table=filt_tbl,\n",
    "    formula=\"C(diet, Treatment('Control'))*C(treatment, Treatment('Ad Lib'))\",\n",
    "    metadata=metadata,\n",
    "    num_iter=100,\n",
    "    chains=4,\n",
    "    beta_prior=5.0,\n",
    "    cauchy_scale=5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-stereo",
   "metadata": {},
   "source": [
    "The Stan model must be compiled before fitting. This should only have to be done once *per model type*. So the second time you use the default `NegativeBinomial` model it will not have to compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.compile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-freeze",
   "metadata": {},
   "source": [
    "Finally, we'll fit the model to our data. This should take ~1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nb.fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-license",
   "metadata": {},
   "source": [
    "## Data structure for model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-model",
   "metadata": {},
   "source": [
    "BIRDMAn makes heavy use of the `arviz` package for downstream analysis (see [documentation](https://arviz-devs.github.io/arviz/index.html)). We provide a wrapper function `to_inference_object` to make this relatively easy.\n",
    "\n",
    "This function wraps much of the functionality of `xarray` for multi-dimensional arrays (see [documentation](http://xarray.pydata.org/en/stable/)). The primary things you have to learn are the `coords` and `dims` system of indexing data.\n",
    "\n",
    "* `dims` corresponds to the dimensionality of the data. In our example, the $\\beta$ parameter is of dimension (number of covariates x number of features), while the $\\phi$ over-dispersion parameter is only of dimension (feature).\n",
    "* `coords` provides the labels for each of the dimensions in `dims`. In this case, we want to specify the name of each covariate and each feature. BIRDMAn saves both of these values as `colnames` and `feature_names` respectively.\n",
    "\n",
    "We also specify that $\\beta$ parameters are currently in *ALR* coordinates. This means that for an input dataset of $N$ microbes, we only have $N-1$ microbes. To address this, we specify that we want the $\\beta$ variable to be transformed into *CLR* coordinates to \"get back\" the microbe we lost.\n",
    "\n",
    "Finally, the last three arguments to this function specify that we want to include several things in the inference object:\n",
    "\n",
    "* `posterior_predictive`: If we tried to predict the feature table entries using the fitted parameters (we do this automatically in the default model) then we can use these values downstream for diagnosing the model. The value for this argument should be the name of the Stan variable containing this information (`y_predict` by default).\n",
    "* `log_likelihood`: We also calculated the log-likelihood values to figure out the best parameter estimates. We can use these values for diagnosis as well. The value for this argument should be the name of the Stan variable containing this information (`log_lik` by default).\n",
    "* `include_observed_data`: This argument specifies whether or not to include the original table values in the inference object. We can use these \"truth\" values to compare our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = nb.to_inference_object(\n",
    "    params=[\"beta\", \"phi\"],\n",
    "    coords={\n",
    "        \"feature\": nb.feature_names,\n",
    "        \"covariate\": nb.colnames\n",
    "    },\n",
    "    dims={\n",
    "        \"beta\": [\"covariate\", \"feature\"],\n",
    "        \"phi\": [\"feature\"]\n",
    "    },\n",
    "    alr_params=[\"beta\"],\n",
    "    posterior_predictive=\"y_predict\",\n",
    "    log_likelihood=\"log_lik\",\n",
    "    include_observed_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-consistency",
   "metadata": {},
   "source": [
    "# Diagnosing our fitted model\n",
    "\n",
    "As with Songbird (or any regression/ML procedure) we want to diagnose our model to make sure we are extracting useful signal and not simply overfitting predictive power. There are a number of ways to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-breakfast",
   "metadata": {},
   "source": [
    "We include an easy to use function to give an *initial* diagnosis for model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.diagnose();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-denial",
   "metadata": {},
   "source": [
    "## LOO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-sheet",
   "metadata": {},
   "source": [
    "Next we look at the Pareto-smoothed Importance Sampling Leave-One-Out Cross-Validation (PSIS-LOO-CV). This is a mouthful but the core of it is that we want to cross-validate our model to make sure we are not overfitting. This can be fairly computationally expensive for Bayesian models so we use an estimation developed by Aki Vehtari and others. This way we can estimate model performance *from the existing sample draws*.\n",
    "\n",
    "See these two papers for more information:\n",
    "\n",
    "* https://arxiv.org/abs/1507.04544\n",
    "* https://arxiv.org/abs/1507.02646\n",
    "\n",
    "**Note:** This function requires that you calculated the `log likelihood` values in your Stan code (done by the default Negative Binomial model) and passed them to the inference object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import birdman.diagnostics as diag\n",
    "\n",
    "diag.loo(inference, pointwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-treasurer",
   "metadata": {},
   "source": [
    "Log likelihood is calculated for each entry in your input table - essentially figuring out how likely is the table value given the estimated parameters. We want to maximize the `elpd_loo` entry. In this demonstration we also calculate the *pointwise* predictive accuracy. We want to see the majority of the Pareto k diagnostic values < 0.7. If there are a lot of values above 0.7 this is indicative of a relatively poor model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-terrorism",
   "metadata": {},
   "source": [
    "## $\\hat{R}$ convergence\n",
    "\n",
    "Another diagnostic tool is making sure your chains are converging. This can be done by checking the $\\hat{R}$ values of your fitted parameters. In a nutshell, these values should be extremely close to 1 to ensure convergence.\n",
    "\n",
    "See [this link](https://arviz-devs.github.io/arviz/api/generated/arviz.rhat.html) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag.rhat(inference).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-flood",
   "metadata": {},
   "source": [
    "We see that across both our covariate coefficients and overdispersion parameters our chains have converged well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-physiology",
   "metadata": {},
   "source": [
    "## Posterior predictive check\n",
    "\n",
    "We can do some more diagnosing by performing a *Posterior Predictive Check*. This procedure essentially uses the parameter distributions we've estimated and tries to predict our original values. We've provided an easy-to-use visualization function that performs this for you. This figure plots the individual table entries (samples x features) and how our model predictions fall. The black line represents the true value, the light gray vertical lines represent the middle 95% interval of values, and the dark gray dots represent the median values from all chains/iterations. We want to see the dark gray lines more-or-less follow the same shape as the black line. It is also preferable to have small credible intervals but predicting microbiome data is very difficult so it is expected that these intervals will be fairly large.\n",
    "\n",
    "Note that this requires posterior predictive values to have been calculated in Stan and provided to `to_inference_object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import birdman.visualization as viz\n",
    "\n",
    "viz.plot_posterior_predictive_checks(inference);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-softball",
   "metadata": {},
   "source": [
    "This model seems to do an okay job of predicting counts from metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-inside",
   "metadata": {},
   "source": [
    "## Comparing to a null model\n",
    "\n",
    "Similarly to Songbird we can compare our fitted regression model to a \"null\" model with only an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdman import NegativeBinomial\n",
    "\n",
    "nb_null = NegativeBinomial(\n",
    "    table=filt_tbl,\n",
    "    formula=\"1\",\n",
    "    metadata=metadata,\n",
    "    num_iter=100,\n",
    "    chains=4\n",
    ")\n",
    "nb_null.compile_model()\n",
    "nb_null.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_null = nb_null.to_inference_object(\n",
    "    params=[\"beta\", \"phi\"],\n",
    "    coords={\n",
    "        \"feature\": nb_null.feature_names,\n",
    "        \"covariate\": nb_null.colnames\n",
    "    },\n",
    "    dims={\n",
    "        \"beta\": [\"covariate\", \"feature\"],\n",
    "        \"phi\": [\"feature\"]\n",
    "    },\n",
    "    alr_params=[\"beta\"],\n",
    "    posterior_predictive=\"y_predict\",\n",
    "    log_likelihood=\"log_lik\",\n",
    "    include_observed_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-stream",
   "metadata": {},
   "source": [
    "We can look at use `birdman.diagnostics.loo` again to see how our predictive power is with this null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag.loo(inference_null, pointwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-mentor",
   "metadata": {},
   "source": [
    "We see a lower value of `elpd_loo`, indicating that this null model has less predictive power than our regression model.\n",
    "\n",
    "Another thing we can do is use the `arviz.compare` function to compare multiple models. This function takes a dictionary in the form of `{\"model_1\": InferenceObject, ...}` and outputs a table where the models are ranked from \"best\" at the top to \"worst\" at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.compare({\"null\": inference_null, \"model\": inference})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-briefs",
   "metadata": {},
   "source": [
    "We see that indeed our regression model is at the top. We can also compare the difference in `elpd` relative to the standard error to get a rough idea of how much better this model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "(-8081.017922 - -8213.895754) / 105.563684"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-fossil",
   "metadata": {},
   "source": [
    "Looks like this model is about 1.25 SE above the null. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-virginia",
   "metadata": {},
   "source": [
    "# Analyzing differentials\n",
    "\n",
    "We are now ready to use our fitted parameters for further analysis.\n",
    "\n",
    "We can now plot our parameter estimates similarly to how we would do a rank-plot in Qurro. However, since in the Bayesian framework each parameter has a distribution, we also include the standard deviation of these parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nb.colnames[1:]:\n",
    "    ax = viz.plot_parameter_estimates(\n",
    "        inference,\n",
    "        parameter=\"beta\",\n",
    "        coord={\"covariate\": col}\n",
    "    )\n",
    "    ax.set_title(\":\\n\".join(col.split(\":\")))\n",
    "    ax.axhline(y=0, color=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-stevens",
   "metadata": {},
   "source": [
    "We can use these differentials in the same ways as Songbird. Let's focus on the diet differentials - first we have to sort the features by their means across all chains and draws. This is fairly straightforward using `xarray`-style indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_diffs = inference.posterior[\"beta\"].sel({\"covariate\": \"C(diet, Treatment('Control'))[T.DIO]\"})\n",
    "diet_diffs = diet_diffs.stack(mcmc_sample=(\"chain\", \"draw\"))\n",
    "diet_diffs_means = diet_diffs.mean(dim=\"mcmc_sample\")\n",
    "diet_diffs_means = diet_diffs_means.sortby(diet_diffs_means)\n",
    "diet_diffs_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-lindsay",
   "metadata": {},
   "source": [
    "## Plotting log-ratios\n",
    "\n",
    "Finally, we'll calculate log-ratios using autoselected OTUs. We'll take the top and bottom 5 OTUs to use as our numerator and denominator respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_ratio(table, top_feats, bot_feats):\n",
    "    num_df = table.loc[:, top_feats].sum(axis=1).to_frame()# + 1\n",
    "    num_df.columns = [\"num\"]\n",
    "    num_df = num_df[num_df[\"num\"] > 0]\n",
    "    denom_df = table.loc[:, bot_feats].sum(axis=1).to_frame()# + 1\n",
    "    denom_df.columns = [\"denom\"]\n",
    "    denom_df = denom_df[denom_df[\"denom\"] > 0]\n",
    "    lr_df = num_df.join(denom_df, how=\"inner\")\n",
    "    lr_df[\"log_ratio\"] = np.log(lr_df[\"num\"]/lr_df[\"denom\"])\n",
    "    return lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_otus = diet_diffs_means[:5].coords[\"feature\"].values\n",
    "top_otus = diet_diffs_means[-5:].coords[\"feature\"].values\n",
    "\n",
    "lr_df = log_ratio(filt_tbl_df.T, top_otus, bottom_otus).join(metadata, how=\"inner\")\n",
    "print(lr_df.shape)\n",
    "lr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-explosion",
   "metadata": {},
   "source": [
    "We'll now plot these log-ratios and compare them by diet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "args = {\n",
    "    \"data\": lr_df,\n",
    "    \"x\": \"diet\",\n",
    "    \"y\": \"log_ratio\"\n",
    "}\n",
    "\n",
    "sns.boxplot(**args)\n",
    "sns.stripplot(**args, linewidth=2, size=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "dio_samples = lr_df.query(\"diet == 'DIO'\")[\"log_ratio\"]\n",
    "control_samples = lr_df.query(\"diet == 'Control'\")[\"log_ratio\"]\n",
    "\n",
    "print(ss.mannwhitneyu(dio_samples, control_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-ladder",
   "metadata": {},
   "source": [
    "Indeed, this log-ratio separates the samples well by diet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-volunteer",
   "metadata": {},
   "source": [
    "We can also use the Hotelling t-Test on individual covariates to see if they are centered around 0 (in ALR coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdman.stats import hotelling_ttest\n",
    "\n",
    "hotelling_ttest(inference, {\"covariate\": \"C(diet, Treatment('Control'))[T.DIO]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
